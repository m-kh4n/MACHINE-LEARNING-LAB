{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MM5XkWvYP0qb"
      },
      "source": [
        "\n",
        "```\n",
        "Machine Learning Lab 05\n",
        "A66\n",
        "MUHAMMAD SHAHNAWAZ KHAN\n",
        "21070461\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_m1JD5_kPNrX"
      },
      "source": [
        "# Aim : Implement ensemble algorithms.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Importing Libraries and IRIS Dataset (Flower Classification)"
      ],
      "metadata": {
        "id": "Q2JxOOwfFkdw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ulnxm5DRDe3H"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Ensemble Model Creation with Help of Random Forrest\n",
        "\n",
        "1. Start by creating a base decision tree model as the foundational component of the ensemble.\n",
        "2. Train multiple decision tree models on different subsets of the training data or with different subsets of features, introducing diversity among individual trees.\n",
        "3. Aggregate predictions from each decision tree to make a final prediction. For classification, this may involve voting; for regression, it typically involves averaging the individual tree predictions.\n",
        "4. Fine-tune hyperparameters, such as tree depth or the number of features considered at each split, to optimize performance and prevent overfitting. Regularization techniques, like limiting tree depth or using a minimum samples per leaf, can enhance the robustness of the ensemble."
      ],
      "metadata": {
        "id": "U0PP9Jz4F3Xx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)\n",
        "\n",
        "# Creation of  base decision tree classifier and a BaggingClassifier (with 10 decision tree classifiers)\n",
        "base_classifier = DecisionTreeClassifier(random_state=42)\n",
        "bagging_classifier = BaggingClassifier(base_classifier, n_estimators=10, random_state=42)\n",
        "\n",
        "# Training, Testing, Evaluating\n",
        "bagging_classifier.fit(X_train, y_train)\n",
        "predictions = bagging_classifier.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "print(f\"Ensemble Accuracy: {accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9c0X8jgQD5n6",
        "outputId": "8e4d3835-5de9-49cf-c015-63d9cda8737b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ensemble Accuracy: 0.9866666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Result Analysis :\n",
        "\n",
        "The accuracy came out to be 98%. Out of all the practicals we have conducted in the lab this is the greatest amount of accuracy a model has been able to generate. Hence we say that ensemble learning is often the best option for accurate model creation.\n"
      ],
      "metadata": {
        "id": "vtSzoohxtQY5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion :\n",
        "\n",
        "Hence we were able to effectively study and implement Ensemble Learning (Random Forrest) using TensorFlow"
      ],
      "metadata": {
        "id": "DSEp0pYKu7KY"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}